# Projet Donn√©es Massives et Cloud - Benchmark TinyInsta

Ce d√©p√¥t contient le code source de l'application **TinyInsta** ainsi que les scripts et les r√©sultats du benchmark de performance r√©alis√© sur Google Cloud Platform (App Engine + Datastore).

L'objectif est d'analyser l'√©volution des performances (temps de r√©ponse de la timeline) en fonction de la charge utilisateurs (concurrence) et de la taille des donn√©es (volume de posts et fanout).

## üîó Liens du Rendu

* **Application D√©ploy√©e :** https://github.com/aminemrh/massive-gcp-projet
* **Code Source :** https://github.com/momo54/massive-gcp

## üìÇ Structure du Projet

Les r√©sultats bruts (CSV) et les graphiques sont situ√©s dans le r√©pertoire `out/`.

* `main.py` : Code source de l'application Flask (Backend).
* `seed.py` : Script de g√©n√©ration de donn√©es (peuplement de la base Datastore).
* `clean.py` : Script utilitaire pour vider la base de donn√©es.
* `benchmark.py` : Script d'automatisation des tests. Il remplace `apache-bench` par une simulation multi-thread√©e pour garantir que chaque requ√™te simule un utilisateur diff√©rent.
* `out/` : Contient les fichiers `conc.csv`, `post.csv`, `fanout.csv` et les graphiques correspondants.

## üöÄ Installation et Reproduction

1.  **Pr√©requis :**
    * Google Cloud SDK install√©.
    * Python 3 install√© avec les librairies : `requests`, `matplotlib`, `pandas`.

2.  **D√©ploiement sur GCP :**
    ```bash
    gcloud app deploy
    ```

3.  **Lancer le Benchmark complet :**
    Ce script nettoie la base, g√©n√®re les donn√©es (seed) pour chaque sc√©nario, lance les tests de charge et g√©n√®re les graphiques.
    ```bash
    python benchmark.py all
    ```

---

## üìä Analyse des R√©sultats

### 1. Passage √† l'√©chelle sur la charge (Concurrence)

**Configuration :** 1000 utilisateurs, 50 posts/user, 20 followers/user.
**Variable :** Nombre d'utilisateurs simultan√©s (1 √† 1000).

![Graphique Concurrence](out/conc.png)
*(Donn√©es brutes : `out/conc.csv`)*

**Analyse :**
On observe une augmentation de la latence jusqu'√† 100 utilisateurs. Cependant, une **chute drastique du temps de r√©ponse** est visible √† 1000 utilisateurs (~200ms).
Ce comportement paradoxal s'explique par l'**Autoscaling** de Google App Engine. D√©tectant une surcharge lors des tests interm√©diaires, la plateforme a provisionn√© de nouvelles instances. La charge de 1000 utilisateurs a donc √©t√© r√©partie sur plusieurs serveurs, r√©duisant la latence per√ßue, l√† o√π une instance unique aurait satur√©.

### 2. Passage √† l'√©chelle sur la taille des donn√©es (Posts)

**Configuration :** 50 requ√™tes simultan√©es, 20 followers/user.
**Variable :** Nombre de posts par utilisateur (10, 100, 1000).

![Graphique Posts](out/post.png)
*(Donn√©es brutes : `out/post.csv`)*

**Analyse :**
Les performances restent globalement stables et acceptables (augmentation lin√©aire faible) m√™me lorsque le volume de posts est multipli√© par 100.
Cela d√©montre l'efficacit√© des **index de Google Datastore**. La requ√™te de timeline r√©cup√©rant les "20 derniers posts", le volume total de l'historique n'impacte que tr√®s peu les performances de lecture.

### 3. Passage √† l'√©chelle sur le Fanout (Followers)

**Configuration :** 50 requ√™tes simultan√©es, 100 posts/user.
**Variable :** Nombre de followers par utilisateur (10, 50, 100).

![Graphique Fanout](out/fanout.png)
*(Donn√©es brutes : `out/fanout.csv`)*

**Analyse :**
C'est le point critique de l'application. On observe une explosion du temps de r√©ponse (> 10 secondes) et l'apparition d'erreurs (**FAILED=1**) √† 100 followers.
La cause est la limitation de l'op√©rateur `IN` du Datastore (limit√© √† 30 valeurs). Au-del√†, l'application ex√©cute s√©quentiellement une requ√™te par ami suivi. Avec 50 utilisateurs simultan√©s suivant 100 personnes, le serveur tente de g√©rer des milliers de requ√™tes en cascade, provoquant saturation et timeouts. L'architecture "Query-on-read" n'est pas adapt√©e ici.

---

## üèÅ Conclusion : Est-ce que √ßa passe √† l'√©chelle ?

L'exp√©rience r√©pond √† la question "Does it scale ?" par la n√©gative pour l'architecture globale, avec des nuances importantes :

1.  **Stockage (‚úÖ OUI) :** L'application passe tr√®s bien √† l'√©chelle sur le volume de donn√©es gr√¢ce √† la nature NoSQL et aux index de Datastore.
2.  **Charge (‚ö†Ô∏è OUI, financi√®rement) :** L'application g√®re la charge massive (1000 utilisateurs) uniquement gr√¢ce √† l'**Autoscaling** du Cloud (ajout de machines), et non par l'efficacit√© du code.
3.  **Logique Sociale (‚ùå NON) :** L'application √©choue √† passer √† l'√©chelle sur le "Fanout". L'architecture na√Øve **"Pull" (Query-on-Read)** sature la base de donn√©es (complexit√© O(N)) d√®s qu'un utilisateur suit plus de 30 personnes.

**Recommandation :** Pour supporter un vrai r√©seau social, il faudrait migrer vers une architecture **"Push" (Fanout-on-Write)**, o√π les timelines sont pr√©-calcul√©es lors de l'√©criture d'un post, rendant la lecture instantan√©e (O(1)).

---

## üë§ Auteur

Projet r√©alis√© dans le cadre du cours "Donn√©es Massives et Cloud".
